{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pejmanrasti/Formation_institut_optique/blob/main/3_TinyCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LwMErUE4nqh"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUaYe-8hrq0a"
      },
      "source": [
        "## Loading Training and Validation Data\n",
        "\n",
        "we use the dataset [CalTech-101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/), which contains around 9000 labeled images belonging to 101 object categories. However, we will exclude 5 of the categories which have the most images. This is in order to keep the class distribution fairly balanced (around 50-100) and constrained to a smaller number of images, around 2935."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19s9e7VgHhmR"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "! pip install TensorBoardColab\n",
        "from tensorflow.keras.models import Sequential,Model # Model type to be used\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout# Make Fully connected (FC) layers\n",
        "from tensorflow.keras.utils import to_categorical # NumPy related tools\n",
        "from tensorflow.keras.callbacks import TensorBoard  #Visulization of Accuracy and loss\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDOVKdaJgaRB"
      },
      "source": [
        "from google.colab import drive\n",
        "root = '/content/gdrive/'\n",
        "drive.mount( root )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6o98dJhgeMz"
      },
      "source": [
        "!unzip gdrive/My\\ Drive/data_IP/101_ObjectCategories.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n14vJSb4jiB3"
      },
      "source": [
        "DATADIR = \"101_ObjectCategories\"\n",
        "CATEGORIES = os.listdir(DATADIR)\n",
        "print(CATEGORIES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = ['BACKGROUND_Google', 'Motorbikes', 'airplanes', 'Faces_easy', 'Faces']\n",
        "print(CATEGORIES)"
      ],
      "metadata": {
        "id": "UpLQbHgNMosq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyJ-fyinlNlT"
      },
      "source": [
        "training_data = []\n",
        "IMG_SIZE_H=224 # you need to set up a numerical value here. Useful to resize to normalize data size\n",
        "IMG_SIZE_W=224 # you need to set up a numerical value here. Useful to resize to normalize data size\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:  # do plants and weeds\n",
        "\n",
        "        path = os.path.join(DATADIR,category)  # create path to the labels\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=plants 1=weeds\n",
        "\n",
        "        for img in os.listdir(path):  # iterate over each image per plants and weeds\n",
        "          if img.endswith('.jpg'):\n",
        "            img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
        "            new_array = cv2.resize(img_array, (IMG_SIZE_H, IMG_SIZE_W))  # resize to normalize data size\n",
        "            training_data.append([new_array, class_num])  # add this to our training_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q74Y7_QzlaGr"
      },
      "source": [
        "create_training_data()  # Calling the function for reading images and labels\n",
        "print(len(training_data)) # Printing the size of the database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7Oa3lXpSOA"
      },
      "source": [
        "Preparation of data for importing to Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcALEpico-eS"
      },
      "source": [
        "random.shuffle(training_data)\n",
        "X = []  # An Array for images\n",
        "y = []  # An Array for labels\n",
        "\n",
        "for features,label in training_data:   # Seperation of iamegs and labels\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "print(np.array(X).shape) # Print the size of the database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRyYO9SUpdug"
      },
      "source": [
        "X = np.array(X).reshape(-1, IMG_SIZE_H, IMG_SIZE_W, 3)  # Reshape data in a form that is suitable for keras\n",
        "print(X.shape) # Print the size of the database"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYXc34napn9n"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyugMSBellom"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDJONvqup8Px"
      },
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5)) # Adjust figsize for better layout\n",
        "for i, ax in enumerate([1, 20, 500]):\n",
        "    axes[i].imshow(X[ax,:,:,:])\n",
        "    axes[i].set_title(f\"Image {ax+1} - Class: {CATEGORIES[y[ax]]}\") # Display class name\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout() # Adjust layout to prevent overlapping\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEFL5miLsJAO"
      },
      "source": [
        "# **Importing necessary Libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_gM34gjBsAW"
      },
      "source": [
        "### First training a neural net from scratch\n",
        "\n",
        "Before doing the transfer learning, let's first build a neural network from scratch for doing classification on our dataset. This will give us a baseline to compare to our transfer-learned network later.\n",
        "\n",
        "The network we will construct contains 4 alternating convolutional and max-pooling layers. After the last pooling layer, we will attach a fully-connected layer with 256 neurons then finally a softmax classification layer for our classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VuttSwGDQdB"
      },
      "source": [
        "# normalize data\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "# one hot encode outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsVz160NDdwF"
      },
      "source": [
        "# build the network\n",
        "model = tf.keras.applications.MobileNet(weights=None, include_top=True)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a reference to VGG's input layer\n",
        "inp = model.input\n",
        "\n",
        "# make a new softmax layer with num_classes neurons\n",
        "new_classification_layer = Dense(5, activation='softmax')\n",
        "\n",
        "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
        "out = new_classification_layer(model.layers[-2].output)\n",
        "\n",
        "# create a new network between inp and out\n",
        "model_new = Model(inp, out)\n",
        "\n",
        "model_new.summary()"
      ],
      "metadata": {
        "id": "wfFFaawv--K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH9KNpw-FMZP"
      },
      "source": [
        "! pip install livelossplot\n",
        "from livelossplot import PlotLossesKeras\n",
        "plotlosses = PlotLossesKeras()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eool4avfx5Eq"
      },
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, verbose=1, mode='auto') #Stop training when a monitored metric has stopped improving.\n",
        "\n",
        "checkpoint_filepath = 'checkpointCNNtiny.keras'\n",
        "Model_check = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto') #Callback to save the Keras model or model weights at some frequency."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2kzBiLRE3Hw"
      },
      "source": [
        "model_new.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_new.fit(X_train, y_train,\n",
        "          validation_data=(X_test, y_test),\n",
        "          epochs=50, batch_size=32,\n",
        "          verbose=1,\n",
        "          callbacks=[plotlosses,early_stop, Model_check])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipCAB6BZMZjh"
      },
      "source": [
        "**Evaluation and Prediction**\n",
        "\n",
        "We can use our model to make a prediction on new images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNFXqmiSOMtp"
      },
      "source": [
        "model_New_load = tf.keras.models.load_model('checkpointCNNtiny.keras')\n",
        "loss, accuracy = model_New_load.evaluate(X_test, y_test, verbose=0) #Evaluation of the model on the test dataset\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfi66rHOF0TG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}